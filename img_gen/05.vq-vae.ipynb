{"cells":[{"cell_type":"code","source":["!pip install umap-learn==0.5.2"],"metadata":{"collapsed":true,"id":"WgHxhXDVfqPM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726838790724,"user_tz":-540,"elapsed":15183,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"6349147c-f97f-4794-ddf2-72b973e18e7f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting umap-learn==0.5.2\n","  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.2) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.2) (1.3.2)\n","Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.2) (1.13.1)\n","Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.2) (0.60.0)\n","Collecting pynndescent>=0.5 (from umap-learn==0.5.2)\n","  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn==0.5.2) (4.66.5)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49->umap-learn==0.5.2) (0.43.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn==0.5.2) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn==0.5.2) (3.5.0)\n","Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: umap-learn\n","  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82686 sha256=3d946bd964630eb0d1ff7eccb691379108e3ad45b8d74ad539de9a93a5558ddf\n","  Stored in directory: /root/.cache/pip/wheels/ff/50/f5/c6dc74059096b9bd10a4446d33ad53748c67850e5c73eb85bd\n","Successfully built umap-learn\n","Installing collected packages: pynndescent, umap-learn\n","Successfully installed pynndescent-0.5.13 umap-learn-0.5.2\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tMnJgsGCfi5E","executionInfo":{"status":"ok","timestamp":1726838850051,"user_tz":-540,"elapsed":59332,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.signal import savgol_filter\n","\n","from six.moves import xrange\n","\n","import umap\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torch.optim as optim\n","\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torchvision.utils import make_grid"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vWjnKIw5fi5E","executionInfo":{"status":"ok","timestamp":1726838850052,"user_tz":-540,"elapsed":5,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["device = torch.device(\"cuda\")\n","# device = torch.devicE(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"huL7g_X8fi5E"},"source":["## Load Data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"cegLzODvfi5E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726838862866,"user_tz":-540,"elapsed":12818,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"e1fba9ad-90f0-4ab0-e278-b7dc4335d092"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 33461283.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/cifar-10-python.tar.gz to data\n","Files already downloaded and verified\n"]}],"source":["training_data = datasets.CIFAR10(root=\"data\", train=True, download=True,\n","                                  transform=transforms.Compose([\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0))\n","                                  ]))\n","\n","validation_data = datasets.CIFAR10(root=\"data\", train=False, download=True,\n","                                  transform=transforms.Compose([\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5,0.5,0.5), (1.0,1.0,1.0))\n","                                  ]))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Z4uQQFBIfi5F","executionInfo":{"status":"ok","timestamp":1726838863849,"user_tz":-540,"elapsed":985,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["data_variance = np.var(training_data.data / 255.0)"]},{"cell_type":"markdown","metadata":{"id":"tS1wDeAhfi5F"},"source":["## Vector Quantizer Layer\n","\n","`BCHW` -> `BHWC` -> `(BHW)C` ((BHW)개 벡터)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"EhubGuVsfi5G","executionInfo":{"status":"ok","timestamp":1726838863850,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["class VectorQuantizer(nn.Module):\n","    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n","        super(VectorQuantizer, self).__init__()\n","\n","        self._embedding_dim = embedding_dim\n","        self._num_embeddings = num_embeddings\n","\n","        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n","        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n","        self._commitment_cost = commitment_cost\n","\n","    def forward(self, inputs):\n","        # convert inputs from BCHW -> BHWC\n","        inputs = inputs.permute(0, 2, 3, 1).contiguous()\n","        input_shape = inputs.shape\n","\n","        # Flatten input\n","        flat_input = inputs.view(-1, self._embedding_dim)\n","\n","        # Calculate distances\n","        distances = (torch.sum(flat_input**2, dim=1, keepdim=True)\n","                    + torch.sum(self._embedding.weight**2, dim=1)\n","                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n","\n","        # Encoding\n","        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n","        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n","        encodings.scatter_(1, encoding_indices, 1)\n","\n","        # Quantize and unflatten\n","        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n","\n","        # Loss\n","        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n","        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n","        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n","\n","        quantized = inputs + (quantized - inputs).detach()\n","\n","        # convert quantized from BHWC -> BCHW\n","        return loss, quantized.permute(0, 3, 1, 2).contiguous(), encodings"]},{"cell_type":"markdown","metadata":{"id":"d3Dwj5Zafi5G"},"source":["## Encoder & Decoder Architecture\n","\n","The encoder and decoder architecture is based on a ResNet and is implemented below:"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"pKLn9u2ufi5G","executionInfo":{"status":"ok","timestamp":1726838863850,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["class Residual(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n","        super(Residual, self).__init__()\n","        self._block = nn.Sequential(\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=in_channels,\n","                      out_channels=num_residual_hiddens,\n","                      kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.ReLU(True),\n","            nn.Conv2d(in_channels=num_residual_hiddens,\n","                      out_channels=num_hiddens,\n","                      kernel_size=1, stride=1, bias=False)\n","        )\n","\n","    def forward(self, x):\n","        return x + self._block(x)\n","\n","\n","class ResidualStack(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(ResidualStack, self).__init__()\n","        self._num_residual_layers = num_residual_layers\n","        self._layers = nn.ModuleList([Residual(in_channels, num_hiddens, num_residual_hiddens)\n","                             for _ in range(self._num_residual_layers)])\n","\n","    def forward(self, x):\n","        for i in range(self._num_residual_layers):\n","            x = self._layers[i](x)\n","        return F.relu(x)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"7ZtzidDdfi5G","executionInfo":{"status":"ok","timestamp":1726838864364,"user_tz":-540,"elapsed":518,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(Encoder, self).__init__()\n","\n","        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n","                                 out_channels=num_hiddens//2,\n","                                 kernel_size=4,\n","                                 stride=2, padding=1)\n","        self._conv_2 = nn.Conv2d(in_channels=num_hiddens//2,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=4,\n","                                 stride=2, padding=1)\n","        self._conv_3 = nn.Conv2d(in_channels=num_hiddens,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=3,\n","                                 stride=1, padding=1)\n","        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n","                                             num_hiddens=num_hiddens,\n","                                             num_residual_layers=num_residual_layers,\n","                                             num_residual_hiddens=num_residual_hiddens)\n","\n","    def forward(self, inputs):\n","        x = self._conv_1(inputs)\n","        x = F.relu(x)\n","\n","        x = self._conv_2(x)\n","        x = F.relu(x)\n","\n","        x = self._conv_3(x)\n","        return self._residual_stack(x)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uZLrHcGjfi5H","executionInfo":{"status":"ok","timestamp":1726838864364,"user_tz":-540,"elapsed":6,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n","        super(Decoder, self).__init__()\n","\n","        self._conv_1 = nn.Conv2d(in_channels=in_channels,\n","                                 out_channels=num_hiddens,\n","                                 kernel_size=3,\n","                                 stride=1, padding=1)\n","\n","        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n","                                             num_hiddens=num_hiddens,\n","                                             num_residual_layers=num_residual_layers,\n","                                             num_residual_hiddens=num_residual_hiddens)\n","\n","        self._conv_trans_1 = nn.ConvTranspose2d(in_channels=num_hiddens,\n","                                                out_channels=num_hiddens//2,\n","                                                kernel_size=4,\n","                                                stride=2, padding=1)\n","\n","        self._conv_trans_2 = nn.ConvTranspose2d(in_channels=num_hiddens//2,\n","                                                out_channels=3,\n","                                                kernel_size=4,\n","                                                stride=2, padding=1)\n","\n","    def forward(self, inputs):\n","        x = self._conv_1(inputs)\n","\n","        x = self._residual_stack(x)\n","\n","        x = self._conv_trans_1(x)\n","        x = F.relu(x)\n","\n","        return self._conv_trans_2(x)"]},{"cell_type":"markdown","metadata":{"id":"pbFvhH_yfi5H"},"source":["## Train"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"dH-pky94fi5H","executionInfo":{"status":"ok","timestamp":1726838864364,"user_tz":-540,"elapsed":5,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["batch_size = 256\n","num_training_updates = 15000\n","\n","num_hiddens = 128\n","num_residual_hiddens = 32\n","num_residual_layers = 2\n","\n","embedding_dim = 64\n","num_embeddings = 512\n","\n","commitment_cost = 0.25\n","\n","decay = 0.99\n","\n","learning_rate = 1e-3"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"iQbdLixYfi5H","executionInfo":{"status":"ok","timestamp":1726838864365,"user_tz":-540,"elapsed":6,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["training_loader = DataLoader(training_data,\n","                             batch_size=batch_size,\n","                             shuffle=True,\n","                             pin_memory=True)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"yFvTMPoOfi5H","executionInfo":{"status":"ok","timestamp":1726838864365,"user_tz":-540,"elapsed":6,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["validation_loader = DataLoader(validation_data,\n","                               batch_size=32,\n","                               shuffle=True,\n","                               pin_memory=True)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"Aym_Xg08fi5H","executionInfo":{"status":"ok","timestamp":1726838864365,"user_tz":-540,"elapsed":6,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["class Model(nn.Module):\n","    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens,\n","                 num_embeddings, embedding_dim, commitment_cost):\n","        super(Model, self).__init__()\n","\n","        self._encoder = Encoder(3, num_hiddens,\n","                                num_residual_layers,\n","                                num_residual_hiddens)\n","        self._pre_vq_conv = nn.Conv2d(in_channels=num_hiddens,\n","                                      out_channels=embedding_dim,\n","                                      kernel_size=1,\n","                                      stride=1)\n","        self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim,\n","                                        commitment_cost)\n","        self._decoder = Decoder(embedding_dim,\n","                                num_hiddens,\n","                                num_residual_layers,\n","                                num_residual_hiddens)\n","\n","    def forward(self, x):\n","        z = self._encoder(x)\n","        z = self._pre_vq_conv(z)\n","        loss, quantized, _ = self._vq_vae(z)\n","        x_recon = self._decoder(quantized)\n","\n","        return loss, x_recon"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"txf-x956fi5H","executionInfo":{"status":"ok","timestamp":1726838864845,"user_tz":-540,"elapsed":485,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["model = Model(num_hiddens, num_residual_layers, num_residual_hiddens,\n","              num_embeddings, embedding_dim,\n","              commitment_cost).to(device)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"qgtns-jVfi5H","executionInfo":{"status":"ok","timestamp":1726838864846,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnzuqbV-fi5H","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be4f9d41-8aff-44f2-d5e1-07dc22a7810f"},"outputs":[{"output_type":"stream","name":"stdout","text":["100 iterations\n","recon_error: 0.706\n","\n","200 iterations\n","recon_error: 0.582\n","\n","300 iterations\n","recon_error: 0.484\n","\n","400 iterations\n","recon_error: 0.400\n","\n","500 iterations\n","recon_error: 0.436\n","\n","600 iterations\n","recon_error: 0.321\n","\n","700 iterations\n","recon_error: 0.302\n","\n","800 iterations\n","recon_error: 0.295\n","\n","900 iterations\n","recon_error: 0.265\n","\n","1000 iterations\n","recon_error: 0.247\n","\n","1100 iterations\n","recon_error: 0.235\n","\n","1200 iterations\n","recon_error: 0.225\n","\n","1300 iterations\n","recon_error: 0.213\n","\n","1400 iterations\n","recon_error: 0.202\n","\n","1500 iterations\n","recon_error: 0.189\n","\n","1600 iterations\n","recon_error: 0.181\n","\n","1700 iterations\n","recon_error: 0.179\n","\n","1800 iterations\n","recon_error: 0.177\n","\n","1900 iterations\n","recon_error: 0.174\n","\n","2000 iterations\n","recon_error: 0.168\n","\n","2100 iterations\n","recon_error: 0.164\n","\n","2200 iterations\n","recon_error: 0.160\n","\n","2300 iterations\n","recon_error: 0.157\n","\n","2400 iterations\n","recon_error: 0.153\n","\n","2500 iterations\n","recon_error: 0.151\n","\n","2600 iterations\n","recon_error: 0.147\n","\n","2700 iterations\n","recon_error: 0.143\n","\n","2800 iterations\n","recon_error: 0.139\n","\n","2900 iterations\n","recon_error: 0.136\n","\n","3000 iterations\n","recon_error: 0.132\n","\n","3100 iterations\n","recon_error: 0.129\n","\n","3200 iterations\n","recon_error: 0.124\n","\n","3300 iterations\n","recon_error: 0.120\n","\n","3400 iterations\n","recon_error: 0.116\n","\n","3500 iterations\n","recon_error: 0.111\n","\n","3600 iterations\n","recon_error: 0.107\n","\n","3700 iterations\n","recon_error: 0.104\n","\n","3800 iterations\n","recon_error: 0.101\n","\n","3900 iterations\n","recon_error: 0.099\n","\n","4000 iterations\n","recon_error: 0.097\n","\n","4100 iterations\n","recon_error: 0.096\n","\n","4200 iterations\n","recon_error: 0.095\n","\n","4300 iterations\n","recon_error: 0.094\n","\n","4400 iterations\n","recon_error: 0.092\n","\n","4500 iterations\n","recon_error: 0.091\n","\n","4600 iterations\n","recon_error: 0.091\n","\n","4700 iterations\n","recon_error: 0.090\n","\n","4800 iterations\n","recon_error: 0.088\n","\n","4900 iterations\n","recon_error: 0.088\n","\n","5000 iterations\n","recon_error: 0.087\n","\n","5100 iterations\n","recon_error: 0.086\n","\n","5200 iterations\n","recon_error: 0.086\n","\n","5300 iterations\n","recon_error: 0.085\n","\n","5400 iterations\n","recon_error: 0.084\n","\n","5500 iterations\n","recon_error: 0.083\n","\n","5600 iterations\n","recon_error: 0.084\n","\n","5700 iterations\n","recon_error: 0.081\n","\n","5800 iterations\n","recon_error: 0.080\n","\n","5900 iterations\n","recon_error: 0.079\n","\n","6000 iterations\n","recon_error: 0.078\n","\n","6100 iterations\n","recon_error: 0.077\n","\n","6200 iterations\n","recon_error: 0.076\n","\n","6300 iterations\n","recon_error: 0.076\n","\n","6400 iterations\n","recon_error: 0.075\n","\n","6500 iterations\n","recon_error: 0.075\n","\n","6600 iterations\n","recon_error: 0.074\n","\n","6700 iterations\n","recon_error: 0.074\n","\n","6800 iterations\n","recon_error: 0.073\n","\n","6900 iterations\n","recon_error: 0.073\n","\n","7000 iterations\n","recon_error: 0.072\n","\n","7100 iterations\n","recon_error: 0.071\n","\n","7200 iterations\n","recon_error: 0.071\n","\n","7300 iterations\n","recon_error: 0.071\n","\n","7400 iterations\n","recon_error: 0.070\n","\n","7500 iterations\n","recon_error: 0.071\n","\n","7600 iterations\n","recon_error: 0.070\n","\n","7700 iterations\n","recon_error: 0.069\n","\n","7800 iterations\n","recon_error: 0.069\n","\n","7900 iterations\n","recon_error: 0.068\n","\n","8000 iterations\n","recon_error: 0.068\n","\n","8100 iterations\n","recon_error: 0.068\n","\n","8200 iterations\n","recon_error: 0.068\n","\n","8300 iterations\n","recon_error: 0.067\n","\n","8400 iterations\n","recon_error: 0.068\n","\n","8500 iterations\n","recon_error: 0.067\n","\n","8600 iterations\n","recon_error: 0.066\n","\n","8700 iterations\n","recon_error: 0.067\n","\n","8800 iterations\n","recon_error: 0.066\n","\n","8900 iterations\n","recon_error: 0.066\n","\n","9000 iterations\n","recon_error: 0.066\n","\n","9100 iterations\n","recon_error: 0.066\n","\n","9200 iterations\n","recon_error: 0.065\n","\n","9300 iterations\n","recon_error: 0.065\n","\n","9400 iterations\n","recon_error: 0.064\n","\n","9500 iterations\n","recon_error: 0.064\n","\n"]}],"source":["model.train()\n","train_res_recon_error = []\n","train_res_perplexity = []\n","\n","for i in xrange(num_training_updates):\n","    (data, _) = next(iter(training_loader))\n","    data = data.to(device)\n","    optimizer.zero_grad()\n","\n","    vq_loss, data_recon = model(data)\n","    recon_error = F.mse_loss(data_recon, data) / data_variance\n","    loss = recon_error + vq_loss\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    train_res_recon_error.append(recon_error.item())\n","\n","    if (i+1) % 100 == 0:\n","        print('%d iterations' % (i+1))\n","        print('recon_error: %.3f' % np.mean(train_res_recon_error[-100:]))\n","        print()"]},{"cell_type":"markdown","metadata":{"id":"C9ZNZP33fi5H"},"source":["## Plot Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AtHVKQfzfi5H"},"outputs":[],"source":["train_res_recon_error_smooth = savgol_filter(train_res_recon_error, 201, 7)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HZOP0RgHfi5H"},"outputs":[],"source":["f = plt.figure(figsize=(16,8))\n","ax = f.add_subplot(1,2,1)\n","ax.plot(train_res_recon_error_smooth)\n","ax.set_yscale('log')\n","ax.set_title('Smoothed NMSE.')\n","ax.set_xlabel('iteration')"]},{"cell_type":"markdown","metadata":{"id":"mt3br7qVfi5I"},"source":["## View Reconstructions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fd5y6JZWfi5I"},"outputs":[],"source":["model.eval()\n","\n","(valid_originals, _) = next(iter(validation_loader))\n","valid_originals = valid_originals.to(device)\n","\n","vq_output_eval = model._pre_vq_conv(model._encoder(valid_originals))\n","_, valid_quantize, _ = model._vq_vae(vq_output_eval)\n","valid_reconstructions = model._decoder(valid_quantize)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Q-RCrKhfi5I"},"outputs":[],"source":["(train_originals, _) = next(iter(training_loader))\n","train_originals = train_originals.to(device)\n","_, train_reconstructions, _ = model._vq_vae(train_originals)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pxh4dt1nfi5I"},"outputs":[],"source":["def show(img):\n","    npimg = img.numpy()\n","    fig = plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","    fig.axes.get_xaxis().set_visible(False)\n","    fig.axes.get_yaxis().set_visible(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X05aVVCffi5I"},"outputs":[],"source":["show(make_grid(valid_reconstructions.cpu().data)+0.5, )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUGCI5HYfi5I"},"outputs":[],"source":["show(make_grid(valid_originals.cpu()+0.5))"]},{"cell_type":"markdown","metadata":{"id":"diKHYWrOfi5I"},"source":["## View Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qVxyjffefi5I"},"outputs":[],"source":["proj = umap.umap_.UMAP(n_neighbors=3,\n","                 min_dist=0.1,\n","                 metric='cosine').fit_transform(model._vq_vae._embedding.weight.data.cpu())"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GaXsB29sfi5I"},"outputs":[],"source":["plt.scatter(proj[:,0], proj[:,1], alpha=0.3)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","toc_visible":true},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}