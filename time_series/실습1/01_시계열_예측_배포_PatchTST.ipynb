{"cells":[{"cell_type":"markdown","metadata":{"id":"mzqyQ-dp8Rir"},"source":["# Time Series Forecasting with Transformer\n","본 실습에서는 변압기를 통해 측정된 ETT (Electricity Transformer Temparature) 데이터셋을 활용한다. 이 데이터에는 전력 부하와 관련된 수치들이 관측되어 있다. 우리는 이 값들이 미래에 어떻게 변하는지를 예측(forecasting)하는 모델을 구현한다. 이를 통해 우리는 미래의 전력 부하를 미리 파악할 수 있고 문제 상황에 미리 대비할 수 있다. 우리는 96개의 관측값을 줬을 때, 96개의 미래 값을 예측하는 테스크를 수행한다."]},{"cell_type":"markdown","metadata":{"id":"XqDqppTG8Riv"},"source":["## 라이브러리 불러오기"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sta2gmejIwn1","executionInfo":{"status":"ok","timestamp":1721371883722,"user_tz":-540,"elapsed":21807,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"d620ac70-95c3-4fe1-9c85-ab521cfef92a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["\n","import os\n","os.chdir('/content/drive/Othercomputers/내 컴퓨터/시계열/실습1')"],"metadata":{"id":"K-UPSmc6I-4L","executionInfo":{"status":"ok","timestamp":1721371884381,"user_tz":-540,"elapsed":662,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGfNu-6zJEdG","executionInfo":{"status":"ok","timestamp":1721371885386,"user_tz":-540,"elapsed":1006,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"272f223d-38f0-4a94-d1a0-04accfcc0b8d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["01_시계열_예측_배포.ipynb\t    checkpoints  __pycache__  test_results\n","01_시계열_예측_배포_PatchTST.ipynb  dataset\t results      utils.py\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"jupyter":{"outputs_hidden":false},"id":"vuApu8QQ8Rix","executionInfo":{"status":"ok","timestamp":1721371937971,"user_tz":-540,"elapsed":7550,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["import argparse\n","import math\n","import random\n","import time\n","import os\n","import warnings\n","import matplotlib\n","from copy import deepcopy\n","import json\n","import torch\n","import numpy as np\n","\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from math import sqrt\n","from matplotlib import pyplot as plt\n","from torch import optim\n","from typing import Tuple, List, Dict, Any, Type\n","\n","from utils import *\n","\n","warnings.filterwarnings('ignore')\n","\n","%matplotlib inline\n","\n","def fix_seed():\n","    random.seed(59683)\n","    torch.manual_seed(59683)\n","    np.random.seed(59683)\n","fix_seed()"]},{"cell_type":"markdown","metadata":{"id":"DgSbcZWo8Ri2"},"source":["## 하이퍼파라미터 세팅\n","하이퍼파라미터는 아래와 같이 고정한다."]},{"cell_type":"code","execution_count":44,"metadata":{"jupyter":{"outputs_hidden":false},"id":"l8H4ObPk8Ri2","executionInfo":{"status":"ok","timestamp":1721372849368,"user_tz":-540,"elapsed":485,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["hyper_param = argparse.Namespace(is_training=1, model_id='ETTm1_96_96', data='ETTm1', task_name = 'long_term_forecast', factor = 3, output_attention = False,\n","                                 root_path='dataset/ETT-small/', data_path='ETTm1.csv',\n","                                 checkpoints='./checkpoints/', seq_len=96, label_len=48,\n","                                 pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=512,\n","                                 n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25,\n","                                 dropout=0.0, activation='gelu', num_workers=10, itr=1, train_epochs=10,\n","                                 batch_size=32, patience=3, learning_rate=0.0001, des='Exp', use_gpu=True, gpu=0)"]},{"cell_type":"markdown","metadata":{"id":"R0aiMMiK8Ri2"},"source":["하이퍼 파라미터에 접근은 아래와 같이 hyper_param.이름 으로 가능하다."]},{"cell_type":"code","execution_count":45,"metadata":{"jupyter":{"outputs_hidden":false},"id":"isWm7E1f8Ri2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721372857264,"user_tz":-540,"elapsed":1057,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"a1ce4d6e-3055-47e6-dd05-9b4d8835031b"},"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","0.0001\n"]}],"source":["print(hyper_param.batch_size)  # 배치 사이즈 접근\n","print(hyper_param.learning_rate)  # learning rate 접근"]},{"cell_type":"markdown","metadata":{"id":"catcxBBO8Ri3"},"source":["GPU 사용을 위해 device를 세팅한다."]},{"cell_type":"code","execution_count":46,"metadata":{"jupyter":{"outputs_hidden":false},"id":"yRH-g3vJ8Ri3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721372857867,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"fd9463d6-ba79-4dcf-beb5-ea41e5ce3aa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Use GPU: cuda:0\n"]}],"source":["device = torch.device('cuda:{}'.format(hyper_param.gpu))\n","print('Use GPU: cuda:{}'.format(hyper_param.gpu))"]},{"cell_type":"markdown","metadata":{"id":"WvGJVt0l8Ri3"},"source":["## 데이터 전처리 및 미리 보기\n","\n","Timeseries forecasting 연구에서 가장 많이 사용되는 데이터셋 중 하나인 ETT (Electricity Transformer Temparature) 데이터셋은 전력 공급과 관련된 모니터링을 위해서 구축된 데이터이다. 2016년 7월 ~ 2018년 7월 기간동안 변압기를 통해 측정되었다. 총 7개의 feature를 가지며, 모두 전력 부하(power load)와 관련된 feature이다.\n","\n","각 feature의 명칭과 간단한 의미는 다음과 같다.\n","\n","| Field | date | HUFL | HULL | MUFL | MULL | LUFL | LULL | OT |\n","| :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |\n","| Description | The recorded **date** |**H**igh **U**se**F**ul **L**oad | **H**igh **U**se**L**ess **L**oad | **M**iddle **U**se**F**ul **L**oad | **M**iddle **U**se**L**ess **L**oad | **L**ow **U**se**F**ul **L**oad | **L**ow **U**se**L**ess **L**oad | **O**il **T**emperature |\n","\n","\n","우리가 사용하는 ETTm1 데이터셋은 ETT 데이터셋 중의 한 종류로써, 15분 간격으로 측정된 데이터셋이다. 학습 데이터, 검증 데이터, 테스트 데이터는 각각 12개월, 4개월, 4개월의 관측치로써, 34,369개, 11,425개, 11,425개의 갯수를 가진다.\n","7개의 feature 외에 시간 정보가 따로 기록되어 있다. 이때 시간 정보는 시간, 요일(1\\~7), 일(1\\~31), 연간 기준 일(1\\~365)이 정규화 과정을 거쳐 [-0.5, 0.5] 사이의 값으로 기록되어 있다."]},{"cell_type":"markdown","metadata":{"id":"yQMWv8sD8Ri3"},"source":["데이터로더를 정의한다. 이때, data_provider함수는 데이터와 데이터로더를 만들어주는 함수이다."]},{"cell_type":"code","source":["class TimeFeature:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        pass\n","\n","    def __repr__(self):\n","        return self.__class__.__name__ + \"()\"\n","\n","\n","class HourOfDay(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.hour / 23.0 - 0.5\n","\n","\n","class DayOfWeek(TimeFeature):\n","    \"\"\"Hour of day encoded as value between [-0.5, 0.5]\"\"\"\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return index.dayofweek / 6.0 - 0.5\n","\n","\n","class DayOfMonth(TimeFeature):\n","    \"\"\"Day of month encoded as value between [-0.5, 0.5]\"\"\"\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.day - 1) / 30.0 - 0.5\n","\n","\n","class DayOfYear(TimeFeature):\n","    \"\"\"Day of year encoded as value between [-0.5, 0.5]\"\"\"\n","\n","    def __call__(self, index: pd.DatetimeIndex) -> np.ndarray:\n","        return (index.dayofyear - 1) / 365.0 - 0.5\n","\n","\n","def time_features(dates):\n","    return np.vstack([feat(dates) for feat in\n","                      [HourOfDay(), DayOfWeek(), DayOfMonth(), DayOfYear()]])\n","\n","\n","class Dataset_ETT_minute(Dataset):\n","    def __init__(self, root_path, flag='train', size=None,\n","                 data_path='ETTm1.csv', scale=True):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 24 * 4 * 4\n","            self.label_len = 24 * 4\n","            self.pred_len = 24 * 4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train': 0, 'val': 1, 'test': 2}\n","        self.set_type = type_map[flag]\n","\n","        self.scale = scale\n","\n","        self.root_path = root_path\n","        self.data_path = data_path\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = pd.read_csv(os.path.join(self.root_path,\n","                                          self.data_path))\n","\n","        border1s = [0, 12 * 30 * 24 * 4 - self.seq_len, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4 - self.seq_len] # 0 : 시작점 , 1 : 1년 데이터 마지막 시퀀스, 2 : 1년 4개월 데이터 마지막 시퀀스\n","        border2s = [12 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 4 * 30 * 24 * 4, 12 * 30 * 24 * 4 + 8 * 30 * 24 * 4] # 0 : 1년 데이터 끝, 1 : 1년 4개월 데이터 끝, 2 : 1년 8개월 데이터 끝\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","\n","        cols_data = df_raw.columns[1:]\n","        df_data = df_raw[cols_data]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","\n","        df_stamp = df_raw[['date']][border1:border2]\n","        df_stamp['date'] = pd.to_datetime(df_stamp.date)\n","        data_stamp = time_features(pd.to_datetime(df_stamp['date'].values))\n","        data_stamp = data_stamp.transpose(1, 0)\n","\n","        self.data_x = data[border1:border2]\n","        self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","\n","    def __getitem__(self, index):\n","      # [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","      # -> [0, 1], [1, 2], [2, 3], [3. 4], [4, 5], [5, 6], [6, 7] ... [8. 9]  길이 = 2, step = 1인 경우\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len # label_len = start token 길이 -> output 시작부분의 앞에 start token이 붙여서 나오니까\n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","\n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len - self.pred_len + 1\n","\n","\n","def data_provider(args, flag):\n","    Data = Dataset_ETT_minute\n","\n","    if flag == 'test':\n","        shuffle_flag = False\n","        drop_last = True\n","        batch_size = args.batch_size\n","    else:\n","        shuffle_flag = True\n","        drop_last = True\n","        batch_size = args.batch_size\n","\n","    data_set = Data(\n","        root_path=args.root_path,\n","        data_path=args.data_path,\n","        flag=flag,\n","        size=[args.seq_len, args.label_len, args.pred_len])\n","    print(flag, len(data_set))\n","    data_loader = DataLoader(\n","        data_set,\n","        batch_size=batch_size,\n","        shuffle=shuffle_flag,\n","        num_workers=args.num_workers,\n","        drop_last=drop_last)\n","    return data_set, data_loader"],"metadata":{"id":"8MDBf4Dq-BCN","executionInfo":{"status":"ok","timestamp":1721372857868,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","execution_count":48,"metadata":{"jupyter":{"outputs_hidden":false},"id":"nhBtkXeS8Ri4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721372859536,"user_tz":-540,"elapsed":528,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"ec8ac850-28a5-45f0-c846-d6de849e3d39"},"outputs":[{"output_type":"stream","name":"stdout","text":["train 34369\n","val 11425\n","test 11425\n"]}],"source":["fix_seed()\n","_, train_loader = data_provider(hyper_param, 'train')\n","_, vali_loader = data_provider(hyper_param, 'val')\n","_, test_loader = data_provider(hyper_param, 'test')"]},{"cell_type":"markdown","metadata":{"id":"r6wSCR098RjE"},"source":["이제 Transformer 구현을 완성해 본다."]},{"cell_type":"code","source":["class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=2,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1, 2)\n","        return x\n","\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4 * d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None, tau=None, delta=None):\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask=attn_mask,\n","            tau=tau, delta=delta\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n","        y = self.dropout(self.conv2(y).transpose(-1, 1))\n","\n","        return self.norm2(x + y), attn\n","\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None, tau=None, delta=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for i, (attn_layer, conv_layer) in enumerate(zip(self.attn_layers, self.conv_layers)):\n","                delta = delta if i == 0 else None\n","                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, tau=tau, delta=None)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask, tau=tau, delta=delta)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns\n","\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4 * d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask,\n","            tau=tau, delta=None\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask,\n","            tau=tau, delta=delta\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1, 1))))\n","        y = self.dropout(self.conv2(y).transpose(-1, 1))\n","\n","        return self.norm3(x + y)\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None, projection=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","        self.projection = projection\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None, tau=None, delta=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask, tau=tau, delta=delta)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        if self.projection is not None:\n","            x = self.projection(x)\n","        return x\n"],"metadata":{"id":"hqDzMSA4xNcC","executionInfo":{"status":"ok","timestamp":1721372859537,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","\n","class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                    torch.arange(H)[None, :, None],\n","                    index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n"],"metadata":{"id":"pqAvbPuIxNHA","executionInfo":{"status":"ok","timestamp":1721372859537,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1. / sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","\n","        if self.output_attention:\n","            return V.contiguous(), A\n","        else:\n","            return V.contiguous(), None\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, d_keys=None,\n","                 d_values=None):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model // n_heads)\n","        d_values = d_values or (d_model // n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","\n","    def forward(self, queries, keys, values, attn_mask, tau=None, delta=None):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask,\n","            tau=tau,\n","            delta=delta\n","        )\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn"],"metadata":{"id":"34tfzBcExM8Q","executionInfo":{"status":"ok","timestamp":1721372861182,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float()\n","                    * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class PatchEmbedding(nn.Module):\n","    def __init__(self, d_model, patch_len, stride, padding, dropout):\n","        super(PatchEmbedding, self).__init__()\n","        # Patching\n","        self.patch_len = patch_len\n","        self.stride = stride\n","        self.padding_patch_layer = nn.ReplicationPad1d((0, padding))\n","\n","        # Backbone, Input encoding: projection of feature vectors onto a d-dim vector space\n","        self.value_embedding = nn.Linear(patch_len, d_model, bias=False)\n","\n","        # Positional embedding\n","        self.position_embedding = PositionalEmbedding(d_model)\n","\n","        # Residual dropout\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        # do patching\n","        n_vars = x.shape[1]\n","        x = self.padding_patch_layer(x)\n","        x = x.unfold(dimension=-1, size=self.patch_len, step=self.stride)\n","        x = torch.reshape(x, (x.shape[0] * x.shape[1], x.shape[2], x.shape[3]))\n","        # Input encoding\n","        x = self.value_embedding(x) + self.position_embedding(x)\n","        return self.dropout(x), n_vars\n"],"metadata":{"id":"iKEXVMLWxM5O","executionInfo":{"status":"ok","timestamp":1721372861182,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["class Transpose(nn.Module):\n","    def __init__(self, *dims, contiguous=False):\n","        super().__init__()\n","        self.dims, self.contiguous = dims, contiguous\n","    def forward(self, x):\n","        if self.contiguous: return x.transpose(*self.dims).contiguous()\n","        else: return x.transpose(*self.dims)\n","\n","\n","class FlattenHead(nn.Module):\n","    def __init__(self, n_vars, nf, target_window, head_dropout=0):\n","        super().__init__()\n","        self.n_vars = n_vars\n","        self.flatten = nn.Flatten(start_dim=-2)\n","        self.linear = nn.Linear(nf, target_window)\n","        self.dropout = nn.Dropout(head_dropout)\n","\n","    def forward(self, x):  # x: [bs x nvars x d_model x patch_num]\n","        x = self.flatten(x)\n","        x = self.linear(x)\n","        x = self.dropout(x)\n","        return x\n","\n","\n","class Model(nn.Module):\n","    \"\"\"\n","    Paper link: https://arxiv.org/pdf/2211.14730.pdf\n","    \"\"\"\n","\n","    def __init__(self, configs, patch_len=16, stride=8):\n","        \"\"\"\n","        patch_len: int, patch len for patch_embedding\n","        stride: int, stride for patch_embedding\n","        \"\"\"\n","        super().__init__()\n","        self.task_name = configs.task_name\n","        self.seq_len = configs.seq_len\n","        self.pred_len = configs.pred_len\n","        padding = stride\n","\n","        # patching and embedding\n","        self.patch_embedding = PatchEmbedding(\n","            configs.d_model, patch_len, stride, padding, configs.dropout)\n","\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(\n","                        FullAttention(False, configs.factor, attention_dropout=configs.dropout,\n","                                      output_attention=configs.output_attention), configs.d_model, configs.n_heads),\n","                    configs.d_model,\n","                    configs.d_ff,\n","                    dropout=configs.dropout,\n","                    activation=configs.activation\n","                ) for l in range(configs.e_layers)\n","            ],\n","            norm_layer=nn.Sequential(Transpose(1,2), nn.BatchNorm1d(configs.d_model), Transpose(1,2))\n","        )\n","\n","        # Prediction Head\n","        self.head_nf = configs.d_model * \\\n","                       int((configs.seq_len - patch_len) / stride + 2)\n","        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n","            self.head = FlattenHead(configs.enc_in, self.head_nf, configs.pred_len,\n","                                    head_dropout=configs.dropout)\n","        elif self.task_name == 'imputation' or self.task_name == 'anomaly_detection':\n","            self.head = FlattenHead(configs.enc_in, self.head_nf, configs.seq_len,\n","                                    head_dropout=configs.dropout)\n","        elif self.task_name == 'classification':\n","            self.flatten = nn.Flatten(start_dim=-2)\n","            self.dropout = nn.Dropout(configs.dropout)\n","            self.projection = nn.Linear(\n","                self.head_nf * configs.enc_in, configs.num_class)\n","\n","    def forecast(self, x_enc, x_mark_enc, x_dec, x_mark_dec):\n","        # Normalization from Non-stationary Transformer\n","        means = x_enc.mean(1, keepdim=True).detach()\n","        x_enc = x_enc - means\n","        stdev = torch.sqrt(\n","            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n","        x_enc /= stdev\n","\n","        # do patching and embedding\n","        x_enc = x_enc.permute(0, 2, 1)\n","        # u: [bs * nvars x patch_num x d_model]\n","        enc_out, n_vars = self.patch_embedding(x_enc)\n","\n","        # Encoder\n","        # z: [bs * nvars x patch_num x d_model]\n","        enc_out, attns = self.encoder(enc_out)\n","        # z: [bs x nvars x patch_num x d_model]\n","        enc_out = torch.reshape(\n","            enc_out, (-1, n_vars, enc_out.shape[-2], enc_out.shape[-1]))\n","        # z: [bs x nvars x d_model x patch_num]\n","        enc_out = enc_out.permute(0, 1, 3, 2)\n","\n","        # Decoder\n","        dec_out = self.head(enc_out)  # z: [bs x nvars x target_window]\n","        dec_out = dec_out.permute(0, 2, 1)\n","\n","        # De-Normalization from Non-stationary Transformer\n","        dec_out = dec_out * \\\n","                  (stdev[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))\n","        dec_out = dec_out + \\\n","                  (means[:, 0, :].unsqueeze(1).repeat(1, self.pred_len, 1))\n","        return dec_out\n","\n","    def imputation(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask):\n","        # Normalization from Non-stationary Transformer\n","        means = torch.sum(x_enc, dim=1) / torch.sum(mask == 1, dim=1)\n","        means = means.unsqueeze(1).detach()\n","        x_enc = x_enc - means\n","        x_enc = x_enc.masked_fill(mask == 0, 0)\n","        stdev = torch.sqrt(torch.sum(x_enc * x_enc, dim=1) /\n","                           torch.sum(mask == 1, dim=1) + 1e-5)\n","        stdev = stdev.unsqueeze(1).detach()\n","        x_enc /= stdev\n","\n","        # do patching and embedding\n","        x_enc = x_enc.permute(0, 2, 1)\n","        # u: [bs * nvars x patch_num x d_model]\n","        enc_out, n_vars = self.patch_embedding(x_enc)\n","\n","        # Encoder\n","        # z: [bs * nvars x patch_num x d_model]\n","        enc_out, attns = self.encoder(enc_out)\n","        # z: [bs x nvars x patch_num x d_model]\n","        enc_out = torch.reshape(\n","            enc_out, (-1, n_vars, enc_out.shape[-2], enc_out.shape[-1]))\n","        # z: [bs x nvars x d_model x patch_num]\n","        enc_out = enc_out.permute(0, 1, 3, 2)\n","\n","        # Decoder\n","        dec_out = self.head(enc_out)  # z: [bs x nvars x target_window]\n","        dec_out = dec_out.permute(0, 2, 1)\n","\n","        # De-Normalization from Non-stationary Transformer\n","        dec_out = dec_out * \\\n","                  (stdev[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n","        dec_out = dec_out + \\\n","                  (means[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n","        return dec_out\n","\n","    def anomaly_detection(self, x_enc):\n","        # Normalization from Non-stationary Transformer\n","        means = x_enc.mean(1, keepdim=True).detach()\n","        x_enc = x_enc - means\n","        stdev = torch.sqrt(\n","            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n","        x_enc /= stdev\n","\n","        # do patching and embedding\n","        x_enc = x_enc.permute(0, 2, 1)\n","        # u: [bs * nvars x patch_num x d_model]\n","        enc_out, n_vars = self.patch_embedding(x_enc)\n","\n","        # Encoder\n","        # z: [bs * nvars x patch_num x d_model]\n","        enc_out, attns = self.encoder(enc_out)\n","        # z: [bs x nvars x patch_num x d_model]\n","        enc_out = torch.reshape(\n","            enc_out, (-1, n_vars, enc_out.shape[-2], enc_out.shape[-1]))\n","        # z: [bs x nvars x d_model x patch_num]\n","        enc_out = enc_out.permute(0, 1, 3, 2)\n","\n","        # Decoder\n","        dec_out = self.head(enc_out)  # z: [bs x nvars x target_window]\n","        dec_out = dec_out.permute(0, 2, 1)\n","\n","        # De-Normalization from Non-stationary Transformer\n","        dec_out = dec_out * \\\n","                  (stdev[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n","        dec_out = dec_out + \\\n","                  (means[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n","        return dec_out\n","\n","    def classification(self, x_enc, x_mark_enc):\n","        # Normalization from Non-stationary Transformer\n","        means = x_enc.mean(1, keepdim=True).detach()\n","        x_enc = x_enc - means\n","        stdev = torch.sqrt(\n","            torch.var(x_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n","        x_enc /= stdev\n","\n","        # do patching and embedding\n","        x_enc = x_enc.permute(0, 2, 1)\n","        # u: [bs * nvars x patch_num x d_model]\n","        enc_out, n_vars = self.patch_embedding(x_enc)\n","\n","        # Encoder\n","        # z: [bs * nvars x patch_num x d_model]\n","        enc_out, attns = self.encoder(enc_out)\n","        # z: [bs x nvars x patch_num x d_model]\n","        enc_out = torch.reshape(\n","            enc_out, (-1, n_vars, enc_out.shape[-2], enc_out.shape[-1]))\n","        # z: [bs x nvars x d_model x patch_num]\n","        enc_out = enc_out.permute(0, 1, 3, 2)\n","\n","        # Decoder\n","        output = self.flatten(enc_out)\n","        output = self.dropout(output)\n","        output = output.reshape(output.shape[0], -1)\n","        output = self.projection(output)  # (batch_size, num_classes)\n","        return output\n","\n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, mask=None):\n","        if self.task_name == 'long_term_forecast' or self.task_name == 'short_term_forecast':\n","            dec_out = self.forecast(x_enc, x_mark_enc, x_dec, x_mark_dec)\n","            return dec_out[:, -self.pred_len:, :]  # [B, L, D]\n","        if self.task_name == 'imputation':\n","            dec_out = self.imputation(\n","                x_enc, x_mark_enc, x_dec, x_mark_dec, mask)\n","            return dec_out  # [B, L, D]\n","        if self.task_name == 'anomaly_detection':\n","            dec_out = self.anomaly_detection(x_enc)\n","            return dec_out  # [B, L, D]\n","        if self.task_name == 'classification':\n","            dec_out = self.classification(x_enc, x_mark_enc)\n","            return dec_out  # [B, N]\n","        return None\n"],"metadata":{"id":"9IwPKcGVxMxR","executionInfo":{"status":"ok","timestamp":1721372861182,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","execution_count":54,"metadata":{"jupyter":{"outputs_hidden":false},"id":"RoLTwgjc8RjG","executionInfo":{"status":"ok","timestamp":1721372861932,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["model = Model(hyper_param).float().to(device)"]},{"cell_type":"markdown","metadata":{"id":"JvGtyVkA8RjH"},"source":["아래 train 함수는 model의 학습 과정이 모두 구현되어 있는 함수이다. 이때, 타겟 시계열 데이터의 start token은 loss계산에 포함되지 않는다."]},{"cell_type":"code","execution_count":55,"metadata":{"jupyter":{"outputs_hidden":false},"id":"RvckxcX28RjI","executionInfo":{"status":"ok","timestamp":1721372863580,"user_tz":-540,"elapsed":2,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["fix_seed()\n","\n","model_optim = optim.Adam(model.parameters(), lr=hyper_param.learning_rate)\n","criterion = nn.MSELoss()"]},{"cell_type":"code","execution_count":56,"metadata":{"jupyter":{"outputs_hidden":false},"id":"zyp4ckxH8RjI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721372864602,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"959f8538-3d39-44c8-ba75-75b3d725f129"},"outputs":[{"output_type":"stream","name":"stdout","text":["ETTm1_96_96_Exp\n"]}],"source":["setting = '{}_{}'.format(hyper_param.model_id, hyper_param.des)\n","print(setting)\n","path = os.path.join(hyper_param.checkpoints, setting)\n","if not os.path.exists(path):\n","    os.makedirs(path)"]},{"cell_type":"code","execution_count":57,"metadata":{"jupyter":{"outputs_hidden":false},"id":"HBZoFiaz8RjI","executionInfo":{"status":"ok","timestamp":1721372864602,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["fix_seed()\n","\n","def train(hyper_param, train_loader, vali_loader, criterion, model):\n","    time_now = time.time()\n","    train_steps = len(train_loader)\n","    # early_stopping = EarlyStopping(patience=hyper_param.patience, verbose=True)\n","    setting = '{}_{}'.format(hyper_param.model_id, hyper_param.des)\n","\n","    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n","    for epoch in range(hyper_param.train_epochs):\n","        iter_count = 0\n","        train_loss = []\n","\n","        model.train()\n","        epoch_time = time.time()\n","        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):\n","            iter_count += 1\n","            model_optim.zero_grad()\n","            batch_x = batch_x.float().to(device)  # [32, 96, 7]\n","            batch_y = batch_y.float().to(device)  # [32, 144, 7]\n","            batch_x_mark = batch_x_mark.float().to(device)  # [32, 96, 4]\n","            batch_y_mark = batch_y_mark.float().to(device)  # [32, 144, 4]\n","\n","            # decoder input\n","            dec_inp = torch.zeros_like(batch_y[:, -hyper_param.pred_len:, :]).float()  # [32, 96, 7]\n","            dec_inp = torch.cat([batch_y[:, :hyper_param.label_len, :], dec_inp], dim=1).float().to(device)  # [32, 48, 7] + [32, 96, 7] = [32, 144, 7]\n","\n","            # encoder - decoder\n","            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","\n","            outputs = outputs[:, -hyper_param.pred_len:]\n","            batch_y = batch_y[:, -hyper_param.pred_len:].to(device)\n","\n","            loss = criterion(outputs, batch_y)\n","            train_loss.append(loss.item())\n","\n","            if (i + 1) % 100 == 0:\n","                print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n","                speed = (time.time() - time_now) / iter_count\n","                left_time = speed * ((hyper_param.train_epochs - epoch) * train_steps - i)\n","                print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n","                iter_count = 0\n","                time_now = time.time()\n","\n","            loss.backward()\n","            model_optim.step()\n","\n","        print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n","        train_loss = np.average(train_loss)\n","        model, vali_loss = vali(hyper_param, vali_loader, criterion, model)\n","\n","        print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f}\".format(epoch + 1, train_steps, train_loss, vali_loss))\n","\n","        # early_stopping(vali_loss, model, path)\n","        # if early_stopping.early_stop:\n","        #     print(\"Early stopping\")\n","        #     break\n","\n","        # adjust_learning_rate(model_optim, epoch + 1, hyper_param)\n","\n","    best_model_path = path + '/' + 'checkpoint.pth'\n","    model.load_state_dict(torch.load(best_model_path))\n","\n","    torch.cuda.empty_cache()\n","    return model"]},{"cell_type":"code","execution_count":58,"metadata":{"jupyter":{"outputs_hidden":false},"id":"i5uGI1T68RjJ","executionInfo":{"status":"ok","timestamp":1721372865436,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["fix_seed()\n","\n","def vali(hyper_param, vali_loader, criterion, model):\n","    total_loss = []\n","    model.eval()\n","    with torch.no_grad():\n","        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(vali_loader):\n","            batch_x = batch_x.float().to(device)\n","            batch_y = batch_y.float()\n","\n","            batch_x_mark = batch_x_mark.float().to(device)\n","            batch_y_mark = batch_y_mark.float().to(device)\n","\n","            # decoder input\n","            dec_inp = torch.zeros_like(batch_y[:, -hyper_param.pred_len:, :]).float()\n","            dec_inp = torch.cat([batch_y[:, :hyper_param.label_len, :], dec_inp], dim=1).float().to(device)\n","            # encoder - decoder\n","            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","            outputs = outputs[:, -hyper_param.pred_len:]\n","            batch_y = batch_y[:, -hyper_param.pred_len:].to(device)\n","\n","            pred = outputs.detach().cpu()\n","            true = batch_y.detach().cpu()\n","\n","            loss = criterion(pred, true)\n","\n","            total_loss.append(loss)\n","    total_loss = np.average(total_loss)\n","    model.train()\n","    return model, total_loss"]},{"cell_type":"code","execution_count":59,"metadata":{"jupyter":{"outputs_hidden":false},"id":"iovDzdK08RjJ","executionInfo":{"status":"ok","timestamp":1721372866031,"user_tz":-540,"elapsed":1,"user":{"displayName":"김태경","userId":"17688271806744859324"}}},"outputs":[],"source":["fix_seed()\n","\n","def test(args, test_loader, model):\n","    print('loading model')\n","    model.load_state_dict(torch.load(os.path.join('./checkpoints/' + setting, 'checkpoint.pth')))\n","\n","    preds = []\n","    trues = []\n","    inputs = []\n","    folder_path = './test_results/' + setting + '/'\n","    if not os.path.exists(folder_path):\n","        os.makedirs(folder_path)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(test_loader):\n","            batch_x = batch_x.float().to(device)\n","            batch_y = batch_y.float().to(device)\n","\n","            batch_x_mark = batch_x_mark.float().to(device)\n","            batch_y_mark = batch_y_mark.float().to(device)\n","\n","            # decoder input\n","            dec_inp = torch.zeros_like(batch_y[:, -hyper_param.pred_len:, :]).float()\n","            dec_inp = torch.cat([batch_y[:, :hyper_param.label_len, :], dec_inp], dim=1).float().to(device)\n","            # encoder - decoder\n","            outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n","\n","            outputs = outputs[:, -hyper_param.pred_len:]\n","            batch_y = batch_y[:, -hyper_param.pred_len:].to(device)\n","            outputs = outputs.detach().cpu().numpy()\n","            batch_y = batch_y.detach().cpu().numpy()\n","            input = batch_x.detach().cpu().numpy()\n","\n","            pred = outputs  # outputs.detach().cpu().numpy()  # .squeeze()\n","            true = batch_y  # batch_y.detach().cpu().numpy()  # .squeeze()\n","\n","            preds.append(pred)\n","            trues.append(true)\n","            inputs.append(input)\n","\n","    preds = np.array(preds)\n","    trues = np.array(trues)\n","    inputs = np.array(inputs)\n","\n","    print('test shape:', preds.shape, trues.shape)\n","    print('input shape:', input.shape)\n","    preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n","    trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n","    inputs = inputs.reshape(-1, inputs.shape[-2], inputs.shape[-1])\n","    print('test shape:', preds.shape, trues.shape)\n","    print('input shape:', input.shape)\n","\n","    # result save\n","    folder_path = './results/' + setting + '/'\n","    if not os.path.exists(folder_path):\n","        os.makedirs(folder_path)\n","\n","    mae, mse = metric(preds, trues)\n","    print('mse:{}, mae:{}'.format(mse, mae))\n","    f = open(\"result.txt\", 'a')\n","    f.write(setting + \"  \\n\")\n","    f.write('mse:{}, mae:{}'.format(mse, mae))\n","    f.write('\\n')\n","    f.write('\\n')\n","    f.close()\n","\n","    np.save(folder_path + 'metrics.npy', np.array([mae, mse]))\n","    np.save(folder_path + 'pred.npy', preds)\n","    np.save(folder_path + 'true.npy', trues)\n","\n","    return preds, trues, inputs"]},{"cell_type":"markdown","metadata":{"id":"5t6iWo9z8RjJ"},"source":["## 모델 학습"]},{"cell_type":"code","execution_count":60,"metadata":{"jupyter":{"outputs_hidden":false},"id":"2RJoAamR8RjJ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1721373224896,"user_tz":-540,"elapsed":357553,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"874d70f7-cac6-4152-8d13-8c6c90e8e825"},"outputs":[{"output_type":"stream","name":"stdout","text":[">>>>>>>start training : ETTm1_96_96_Exp>>>>>>>>>>>>>>>>>>>>>>>>>>\n","\titers: 100, epoch: 1 | loss: 0.3315878\n","\tspeed: 0.0495s/iter; left time: 526.5574s\n","\titers: 200, epoch: 1 | loss: 0.3567612\n","\tspeed: 0.0461s/iter; left time: 486.4025s\n","\titers: 300, epoch: 1 | loss: 0.2880337\n","\tspeed: 0.0466s/iter; left time: 486.4959s\n","\titers: 400, epoch: 1 | loss: 0.3485309\n","\tspeed: 0.0466s/iter; left time: 481.4508s\n","\titers: 500, epoch: 1 | loss: 0.2506832\n","\tspeed: 0.0467s/iter; left time: 478.1416s\n","\titers: 600, epoch: 1 | loss: 0.2590888\n","\tspeed: 0.0480s/iter; left time: 487.2260s\n","\titers: 700, epoch: 1 | loss: 0.2422698\n","\tspeed: 0.0474s/iter; left time: 476.4232s\n","\titers: 800, epoch: 1 | loss: 0.2651143\n","\tspeed: 0.0472s/iter; left time: 469.3747s\n","\titers: 900, epoch: 1 | loss: 0.2471462\n","\tspeed: 0.0473s/iter; left time: 465.6916s\n","\titers: 1000, epoch: 1 | loss: 0.2738378\n","\tspeed: 0.0478s/iter; left time: 465.7247s\n","Epoch: 1 cost time: 51.00467610359192\n","Epoch: 1, Steps: 1074 | Train Loss: 0.2971300 Vali Loss: 0.4175951\n","\titers: 100, epoch: 2 | loss: 0.2288615\n","\tspeed: 0.1430s/iter; left time: 1367.6439s\n","\titers: 200, epoch: 2 | loss: 0.2474872\n","\tspeed: 0.0483s/iter; left time: 457.1473s\n","\titers: 300, epoch: 2 | loss: 0.3470138\n","\tspeed: 0.0479s/iter; left time: 448.6273s\n","\titers: 400, epoch: 2 | loss: 0.3420395\n","\tspeed: 0.0483s/iter; left time: 447.8428s\n","\titers: 500, epoch: 2 | loss: 0.2097792\n","\tspeed: 0.0486s/iter; left time: 445.9190s\n","\titers: 600, epoch: 2 | loss: 0.2004386\n","\tspeed: 0.0484s/iter; left time: 438.7793s\n","\titers: 700, epoch: 2 | loss: 0.2210881\n","\tspeed: 0.0482s/iter; left time: 432.3778s\n","\titers: 800, epoch: 2 | loss: 0.2307679\n","\tspeed: 0.0486s/iter; left time: 430.5150s\n","\titers: 900, epoch: 2 | loss: 0.1944873\n","\tspeed: 0.0487s/iter; left time: 426.6570s\n","\titers: 1000, epoch: 2 | loss: 0.2770393\n","\tspeed: 0.0487s/iter; left time: 421.7247s\n","Epoch: 2 cost time: 52.44248294830322\n","Epoch: 2, Steps: 1074 | Train Loss: 0.2644370 Vali Loss: 0.4158507\n","\titers: 100, epoch: 3 | loss: 0.2529094\n","\tspeed: 0.1538s/iter; left time: 1306.2718s\n","\titers: 200, epoch: 3 | loss: 0.2642029\n","\tspeed: 0.0490s/iter; left time: 411.6272s\n","\titers: 300, epoch: 3 | loss: 0.2115986\n","\tspeed: 0.0493s/iter; left time: 408.8887s\n","\titers: 400, epoch: 3 | loss: 0.1736585\n","\tspeed: 0.0492s/iter; left time: 403.0096s\n","\titers: 500, epoch: 3 | loss: 0.2803260\n","\tspeed: 0.0491s/iter; left time: 397.7162s\n","\titers: 600, epoch: 3 | loss: 0.2557935\n","\tspeed: 0.0495s/iter; left time: 395.9598s\n","\titers: 700, epoch: 3 | loss: 0.2321080\n","\tspeed: 0.0501s/iter; left time: 395.7894s\n","\titers: 800, epoch: 3 | loss: 0.2656048\n","\tspeed: 0.0497s/iter; left time: 387.1520s\n","\titers: 900, epoch: 3 | loss: 0.1963083\n","\tspeed: 0.0495s/iter; left time: 380.6007s\n","\titers: 1000, epoch: 3 | loss: 0.2435981\n","\tspeed: 0.0498s/iter; left time: 378.1442s\n","Epoch: 3 cost time: 53.48046588897705\n","Epoch: 3, Steps: 1074 | Train Loss: 0.2470946 Vali Loss: 0.4324176\n","\titers: 100, epoch: 4 | loss: 0.2138907\n","\tspeed: 0.1477s/iter; left time: 1095.4254s\n","\titers: 200, epoch: 4 | loss: 0.2369481\n","\tspeed: 0.0497s/iter; left time: 364.1107s\n","\titers: 300, epoch: 4 | loss: 0.2751280\n","\tspeed: 0.0496s/iter; left time: 358.4156s\n","\titers: 400, epoch: 4 | loss: 0.2358973\n","\tspeed: 0.0498s/iter; left time: 354.7301s\n","\titers: 500, epoch: 4 | loss: 0.1990343\n","\tspeed: 0.0500s/iter; left time: 351.2959s\n","\titers: 600, epoch: 4 | loss: 0.2058351\n","\tspeed: 0.0498s/iter; left time: 344.7341s\n","\titers: 700, epoch: 4 | loss: 0.2992894\n","\tspeed: 0.0497s/iter; left time: 338.8903s\n","\titers: 800, epoch: 4 | loss: 0.3382879\n","\tspeed: 0.0501s/iter; left time: 336.4572s\n","\titers: 900, epoch: 4 | loss: 0.2523590\n","\tspeed: 0.0499s/iter; left time: 330.4854s\n","\titers: 1000, epoch: 4 | loss: 0.2047155\n","\tspeed: 0.0498s/iter; left time: 324.3664s\n","Epoch: 4 cost time: 54.08192467689514\n","Epoch: 4, Steps: 1074 | Train Loss: 0.2315544 Vali Loss: 0.4543204\n","\titers: 100, epoch: 5 | loss: 0.1727476\n","\tspeed: 0.1565s/iter; left time: 992.7851s\n","\titers: 200, epoch: 5 | loss: 0.2065901\n","\tspeed: 0.0504s/iter; left time: 314.9313s\n","\titers: 300, epoch: 5 | loss: 0.2472277\n","\tspeed: 0.0507s/iter; left time: 311.3532s\n","\titers: 400, epoch: 5 | loss: 0.2286887\n","\tspeed: 0.0500s/iter; left time: 302.4702s\n","\titers: 500, epoch: 5 | loss: 0.2280915\n","\tspeed: 0.0498s/iter; left time: 295.9118s\n","\titers: 600, epoch: 5 | loss: 0.2706796\n","\tspeed: 0.0502s/iter; left time: 293.5618s\n","\titers: 700, epoch: 5 | loss: 0.2212857\n","\tspeed: 0.0503s/iter; left time: 288.7171s\n","\titers: 800, epoch: 5 | loss: 0.2135717\n","\tspeed: 0.0500s/iter; left time: 282.1805s\n","\titers: 900, epoch: 5 | loss: 0.1700320\n","\tspeed: 0.0502s/iter; left time: 278.1733s\n","\titers: 1000, epoch: 5 | loss: 0.2786741\n","\tspeed: 0.0505s/iter; left time: 274.8272s\n","Epoch: 5 cost time: 54.3096981048584\n","Epoch: 5, Steps: 1074 | Train Loss: 0.2151058 Vali Loss: 0.4672846\n","\titers: 100, epoch: 6 | loss: 0.2371207\n","\tspeed: 0.1493s/iter; left time: 786.9689s\n","\titers: 200, epoch: 6 | loss: 0.2518237\n","\tspeed: 0.0503s/iter; left time: 260.1785s\n","\titers: 300, epoch: 6 | loss: 0.1753224\n","\tspeed: 0.0501s/iter; left time: 253.8615s\n","\titers: 400, epoch: 6 | loss: 0.2102638\n","\tspeed: 0.0502s/iter; left time: 249.6406s\n","\titers: 500, epoch: 6 | loss: 0.1868586\n","\tspeed: 0.0506s/iter; left time: 246.5014s\n","\titers: 600, epoch: 6 | loss: 0.2054171\n","\tspeed: 0.0502s/iter; left time: 239.3297s\n","\titers: 700, epoch: 6 | loss: 0.1917608\n","\tspeed: 0.0502s/iter; left time: 234.5607s\n","\titers: 800, epoch: 6 | loss: 0.1638770\n","\tspeed: 0.0506s/iter; left time: 231.2569s\n","\titers: 900, epoch: 6 | loss: 0.1807918\n","\tspeed: 0.0505s/iter; left time: 225.5899s\n","\titers: 1000, epoch: 6 | loss: 0.1806714\n","\tspeed: 0.0503s/iter; left time: 219.7438s\n","Epoch: 6 cost time: 54.515909910202026\n","Epoch: 6, Steps: 1074 | Train Loss: 0.1973857 Vali Loss: 0.4568742\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-2ca37566d196>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfix_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvali_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-57-ae7663601093>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(hyper_param, train_loader, vali_loader, criterion, model)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_x_mark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_mark\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0miter_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RecordFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;31m# use `self_` to avoid naming collide with aten ops arguments that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;31m# are named \"self\". This way, all the aten ops can be called by kwargs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["fix_seed()\n","model = train(hyper_param, train_loader, vali_loader, criterion, model)"]},{"cell_type":"markdown","metadata":{"id":"n62xkp318RjK"},"source":["## 모델 평가"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"qb8rJAB38RjK","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"error","timestamp":1720623377520,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"812fc9df-9f5c-4f23-d720-1876ad91c6ab"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'setting' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-57a4fa6cb81a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfix_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'setting' is not defined"]}],"source":["fix_seed()\n","\n","print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n","preds, trues, inputs = test(hyper_param, test_loader, model)\n","torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"FfBBOy698RjK"},"source":["## 모델 결과 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"u6_2rea68RjK","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"error","timestamp":1720623377520,"user_tz":-540,"elapsed":3,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"f6a3de56-5999-4738-c2a7-ab04b7ace994"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'inputs' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-f513386d022a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mpost_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"]}],"source":["def post_vis(data_num, feature_num, inputs=inputs, preds=preds, trues=trues):\n","    gt = np.concatenate((inputs[data_num, :, feature_num], trues[data_num, :, feature_num]), axis=0)\n","    pd = np.concatenate((inputs[data_num, :, feature_num], preds[data_num, :, feature_num]), axis=0)\n","    plt.figure(dpi=100)\n","    plt.plot(pd, label='prediction')\n","    plt.plot(gt, label='ground truth')\n","    plt.legend()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"outputs_hidden":false},"id":"pGFQuuJq8RjL","colab":{"base_uri":"https://localhost:8080/","height":184},"executionInfo":{"status":"error","timestamp":1720623378397,"user_tz":-540,"elapsed":4,"user":{"displayName":"김태경","userId":"17688271806744859324"}},"outputId":"cd9755c8-46a9-4306-ca6e-f1d1a0535f66"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'post_vis' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-d5611b0c1a63>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfeature_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpost_vis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'post_vis' is not defined"]}],"source":["data_num = 0\n","feature_num = 0\n","post_vis(data_num, feature_num)"]},{"cell_type":"code","source":[],"metadata":{"id":"gICEvP5EJStd"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}